* -> drives implicit enumeration
* => drives implicit reduction
* implicit enumeration allows the compiler to generate more optimal code for a loop
  - better vectorization
  - better abstraction (hiding loop implementation details)
  - looser coupling between components of an algorithm
* <source> -> or => ... -> <mapping>
* <source> -> or => ... => <sink>
* <source> can be any of the following:
  - an aggregate (stream, list, array, other containers)
  - a separate process working as a generator
  - a buffered generator (allowing to enumerate it more than once)
  - an OS process
  - a special stream type (blocking stream, event stream, etc.)
* atomic values are implicitly converted to streams of one element
  - an atomic value is one of: atom, scalar, string, vector, tuple
* some atomic values can be converted to longer streams,
  e.g. string -> stream of bytes (or stream of codepoints)
       vector -> stream of coordinates
* all of the components that take part in a given stream enumeration form a single higher level component
* the compiler can optimize a single component as a whole,
  inlining and eliminating operations as long as the semantics stays the same
* errors encountered during an enumeration flow in a separate channel back to the caller
* the caller may choose to ignore errors (then they propagate to the top of the call stack)
* the caller may choose to setup condition handlers for errors (see Common Lisp conditions; Rust)
* side effects inside an enumeration occur at known synchronization points
* side-effect-less enumeration can be optimizied more aggresively by the compiler
* the language evaluates expressions eagerly, but can support lazy streams
* enumeration can be done sequentially, concurrently, or in parallel -- the interface remains the same


>> Example: Parallel map <<

// map all elements of an array to their respective squares, in parallel
let nums = array(1..100)
let squares_sequential 
         = nums -> fn(x) { x * x } => array()
let squares 
         = parallel(nums) -> fn(x) { x * x } => array()

* That is, the mechanics of enumeration are determined entirely by the source.
  The code shape is independent of the what is going on under the hood.


>> Example: List monad <<

let nums = array(1, 2, 3)
let perms1 = list_monad(nums) => array()  // [(1,), (2,), (3,)]
let perms2 = list_monad(nums, nums) => array()  // [(1,1), (1,2), (1,3), (2,1), (2,2), (2,3), (3,1), (3,2), (3,3)]
let perms3 = list_monad(fn() {
    let x = nums
    let y = nums
    return (x, y)
}) => array()


## Important points of a new language ##

* Controlled side effects and mutability lead to
  1) better abstraction
  2) better optimization opportunities
* Mutable state should be employed locally, for performance goals
* Encoding state in a few established "places" helps make program automatically parallelizable/distributable

* Conditions provide greater flexibility than exceptions and potentially better code reuse
* Standard error propagation mechanism frees the programmer of boiler-plate, helps write code that fails early
* Freeing ordinary code from error handling provides an abstraction that helps in separation of concerns
  (helps getting rid of ad-hoc and hence poor-quality error reporting)

* Generic programming helps in code reuse
* Operator overloading helps keep the syntax under control
* Compiler should be able to reason about types and traits to provide good optimization

* Boilerplate can be eliminated using macros
* Macros don't have to be the same language (think scripting/embedded language)

* Iteration should be a first-class abstraction to provide
  1) conciseness
  2) separation of concerns
  3) performance

* Making sense of operator overloading:

    a + b

  The expression above should make sense for the following types of a and b:
  - integer
  - float
  - rational
  - vector
  - matrix
  - complex number
  - decimal float
  - any other type with addition defined

  What if the types of the operands do not match?
  a) define type promotion rules
  b) forbid automatic conversion
  c) look at the type of the whole expr (whether by casting or by assigning to a variable)
     and convert the operands accordingly

  The general guideline is: the result type is specified (by annotation or
  assignment) and the compiler should use it as a hint. Specifying conversion
  for each operand is redundant because the types of the operands define the
  semantics of the operations.

  For the cases of different operand types, it should be possible to specify a
  promotion context, inside which all types will be promoted to the specified
  type prior to performing the operations.

  Specifically, in this example
       
      var result complex
      var a float
      var b int
      result = a / b

  the code does not compile because the type the "a/b" expression is not complex.

  However, this could work

      result = a / b :: complex

  if there is a defined conversion from float to compex.

  ---------------

  What about this:

      var result float
      var a, b int
      result = a / b

  In this case, we cannot automatically promote "a / b" because the user
  might want the truncated division. This code won't compile because
  assigning int to float is bad.

  ----------------

  What if the user does want floating-point division?

      result = float(a / b)

  Here, instead of promoting one operand to float, we denote a "floating point context", inside which
  all values will be converted to float. Does it make sense? Could be confusing in practice.

      var a, b complex
      result = float(a + b)  // error: no conversion from complex to float

      var a, b float
      var result int
      result = a / b         // error: automatic truncation to int not allowed
      result = a / b :: int  // OK, result truncated

      result = int(a / b)    // OK?, integer division

      var ai, bi int
      ai = a :: int
      bi = b :: int
      result = ai / bi       // OK, integer division

  What about

      var a, b, c float
      var result int
      result = (a + b * c) / (2 * c) :: int   // OK, result truncated
      result = int((a + b*c) / (2*c))         // all converted to int prior to evaluation

      result = ceil((a + b*c) / (2*c)) :: int // OK, wraps up before truncating to int
      result = int(a + ceil(2/c)) :: int      // OK, "2/c" produces a float

      var a int
      var b float

      c = int(a / b)          // integer division
      result = a + c :: float

      ** vs **

      result = float32(a + a / int32(b))

  ** Nested contexts should be forbidden -- too much confusion.

      result = float(a + int(a / b))        // OK?
      result = float(a + float(a / b):int)  // OK?, result of division truncated
      result = float(a + a / b:int)    // OK, b truncated before float division
      result = a + a / b:int :: float  // OK, integer ops followed by conversion to float 

  ---------------------

      result = a / b :: float   // OK


Static binding vs Late binding
==============================

* Must have different syntax
* Allows for control over code dynamism
* For things like apply(function_name, [arg1, arg2, ...]) to work,
  the function that is called needs to be declared as dynamic

#[static-dispatch]
class StaticObj {
    void method1();
    virtual void method2();  // virtual dispatch
    dynamic void method3();  // dynamic dispatch
};

- OR -

class StaticObj {
    void method1();
    void method2();
    void method3();
} @dynamic: method1;

----------------------

#[dynamic-dispatch, all-methods-dynamic]
class DynamicObj {
    void method1(); // dynamic dispatch
    void method2(); // dynamic dispatch

    static void method4(); // static dispatch

private:
    void method3();  // static dispatch
};

-----------------------

class Obj {
dynamic:
    void method1();
    void method2();

static:
    void method3();
    void method4();

virtual:
    void method5();
    void method6();

private:
    // all static here
    void method7();
    void method8();
};


// Static dispatch
obj.method(1, "string", ptr);

// Virtual dispatch
ifacevalue.method(...);

// Dynamic dispatch
[obj method:1, "string", ptr];
obj..method(1, "string", ptr);
obj.*.method(1, "string", ptr);
obj:method(1, "string", ptr);
obj.method.(1, "string", ptr);
obj∎method(1, "string", ptr);
obj‣method(1, "string", ptr);
obj▻method(1, "string", ptr);
obj⇒method(1, "string", ptr);

// Dynamic call
obj⇒call("method", [1, "string", ptr]);
call(obj, "method", [1, "string", ptr]);

// So the object's class declaration doesn't need to have separation into
// "static" and "dynamic". Those are just possible optimizations.
class Obj {
public:
    void method1();
    void method2();

private:
    void method3();
    void method4();
} @static method1;

#[all-methods-static]
class Obj {
    // ... only static dispatch with no export of meta-data by the compiler
};
